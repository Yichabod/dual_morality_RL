{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid import Grid\n",
    "import numpy as np\n",
    "from agent import Agent\n",
    "import time\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_grids(amount=1000, size=5):\n",
    "    grids = []\n",
    "    for j in range(amount):\n",
    "        grids.append(Grid(size, random=True))\n",
    "    with open('test_grids.pickle', 'wb') as fil:\n",
    "        pickle.dump(grids, fil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_test_grids(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_grids():\n",
    "    with open('test_grids.pickle', 'rb') as fil:\n",
    "        grids = pickle.load(fil)\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = load_test_grids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_MC_first_visit(testgrids, iterations=100, model_based=True, nn_init=False):\n",
    "    reward_dist = {}\n",
    "    rewards = []\n",
    "    for testgrid in testgrids:\n",
    "        a = Agent()\n",
    "        if model_based:\n",
    "            Q, policy = a.mc_first_visit_control(testgrid.copy(), iterations, nn_init=nn_init) # Q value key is (self.agent_pos,self.train.pos,list(self.other_agents.positions)[0])\n",
    "            grids, action_values, reward = a.run_final_policy(testgrid.copy(), Q, nn_init=nn_init)\n",
    "        else:\n",
    "            reward = a.run_model_free_policy(testgrid.copy())\n",
    "        if reward not in reward_dist:\n",
    "            reward_dist[reward] = 1\n",
    "        else:\n",
    "            reward_dist[reward] += 1\n",
    "        rewards.append(reward)\n",
    "        \n",
    "    return np.mean(rewards), reward_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.933 {0: 718, -5: 123, -2: 159}\n",
      "1 -0.8985 {0: 718, -5: 114, -2: 156, -0.2: 4, -2.2: 1, -0.5: 5, -5.5: 2}\n",
      "3 -0.7858999999999999 {0: 733, -5: 91, -2: 151, -5.2: 1, -0.5: 9, -0.2: 10, -7.5: 1, -5.5: 1, -2.2: 1, -1.0: 2}\n",
      "10 -0.43439999999999995 {0: 787, -5.5: 1, -2: 138, -0.2: 34, -5: 24, -5.2: 3, -0.5: 11, -2.5: 2}\n",
      "30 -0.27640000000000003 {0: 817, -0.2: 57, -2: 115, -5: 5, -0.5: 5, -7.5: 1}\n",
      "100 -0.23160000000000003 {0: 814, -0.2: 73, -2: 107, -0.5: 6}\n"
     ]
    }
   ],
   "source": [
    "iterations = [0, 1, 3, 10, 30, 100]#, 300, 1000]\n",
    "mb_scores = []\n",
    "\n",
    "mb_agent_deaths = []\n",
    "mb_other_deaths = []\n",
    "mb_switch_uses = []\n",
    "mb_pushes = []\n",
    "mb_nothing = []\n",
    "mb_other = []\n",
    "\n",
    "for it in iterations:\n",
    "    score, reward_dist = test_MC_first_visit(grids, it, nn_init=False)\n",
    "    print(it, score, reward_dist)\n",
    "    mb_agent_deaths.append(0)\n",
    "    mb_other_deaths.append(0)\n",
    "    mb_switch_uses.append(0)\n",
    "    mb_pushes.append(0)\n",
    "    mb_nothing.append(0)\n",
    "    mb_other.append(0)\n",
    "    for key in reward_dist:\n",
    "        if key<=-5:\n",
    "            mb_agent_deaths[-1] += reward_dist[key]\n",
    "        elif key <=-2:\n",
    "            mb_other_deaths[-1] += reward_dist[key]\n",
    "        elif key == -0.5:\n",
    "            mb_pushes[-1] += reward_dist[key]\n",
    "        elif key ==-0.2:\n",
    "            mb_switch_uses[-1] += reward_dist[key]\n",
    "        elif key ==0:\n",
    "            mb_nothing[-1] += reward_dist[key]\n",
    "        else:\n",
    "            mb_other[-1] += reward_dist[key]\n",
    "        \n",
    "    mb_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.30629999999999996 {0: 778, -2: 127, -5: 2, -0.2: 59, -0.4: 12, -2.2: 8, -0.8: 2, -0.5: 8, -0.7: 1, -0.6000000000000001: 3}\n",
      "1 -0.2653 {0: 804, -2: 118, -0.2: 58, -2.2: 4, -0.8: 2, -0.5: 7, -0.4: 5, -1.2: 1, -0.6000000000000001: 1}\n",
      "3 -0.2562 {0: 806, -0.2: 62, -2: 113, -2.4000000000000004: 1, -0.4: 6, -2.4: 1, -2.2: 3, -0.5: 8}\n",
      "10 -0.22690000000000002 {0: 820, -0.2: 66, -2: 101, -0.4: 1, -2.2: 3, -0.5: 8, -0.7: 1}\n",
      "30 -0.20650000000000002 {0: 828, -0.2: 69, -2: 94, -0.5: 8, -0.7: 1}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "agent_deaths = []\n",
    "other_deaths = []\n",
    "switch_uses = []\n",
    "pushes = []\n",
    "nothing = []\n",
    "other = []\n",
    "\n",
    "for it in iterations:\n",
    "    score, reward_dist = test_MC_first_visit(grids, it, nn_init=True)\n",
    "    print(it, score, reward_dist)\n",
    "    agent_deaths.append(0)\n",
    "    other_deaths.append(0)\n",
    "    switch_uses.append(0)\n",
    "    pushes.append(0)\n",
    "    nothing.append(0)\n",
    "    other.append(0)\n",
    "    for key in reward_dist:\n",
    "        if key<=-5:\n",
    "            agent_deaths[-1] += reward_dist[key]\n",
    "        elif key <=-2:\n",
    "            other_deaths[-1] += reward_dist[key]\n",
    "        elif key == -0.5:\n",
    "            pushes[-1] += reward_dist[key]\n",
    "        elif key ==-0.2:\n",
    "            switch_uses[-1] += reward_dist[key]\n",
    "        elif key ==0:\n",
    "            nothing[-1] += reward_dist[key]\n",
    "        else:\n",
    "            other[-1] += reward_dist[key]\n",
    "        \n",
    "    scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, agent_deaths)\n",
    "plt.plot(iterations, other_deaths)\n",
    "plt.plot(iterations, switch_uses)\n",
    "plt.plot(iterations, pushes)\n",
    "plt.plot(iterations, nothing)\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [agent_deaths[0], other_deaths[0], switch_uses[0], pushes[0], nothing[0], other[0]]\n",
    "labels = [\"Agent dies\", \"Other person dies\", \"Switch used\", \"Agent pushes other\", \"Nothing\", \"Other\"]\n",
    "plt.pie(events, labels=labels)\n",
    "#plt.bar([i for i in range(len(events))], events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_agent_deaths[-1], mb_other_deaths[-1], mb_switch_uses[-1], mb_pushes[-1], mb_nothing[-1], mb_other[-1]]\n",
    "labels = [\"Agent dies\", \"Other person dies\", \"Switch used\", \"Agent pushes other\", \"Nothing\", \"Other\"]\n",
    "plt.pie(events, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations, mb_scores, label = \"Original MC-first visit\")\n",
    "plt.plot(iterations, scores, label = \"MC-first visit with NN-initialization\")\n",
    "plt.xlabel(\"MC-first visit iterations\")\n",
    "plt.ylabel(\"Average reward on test scenarios\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_agent_deaths[0], agent_deaths[0], mb_agent_deaths[5], agent_deaths[5]]\n",
    "plt.bar([i for i in range(len(events))], events, tick_label=['Do nothing','NN','MC 100 iter'\n",
    "                                                             ,'MC-NN 100 iter'])\n",
    "\n",
    "plt.ylabel('Agent deaths/1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_other_deaths[0], other_deaths[0], mb_other_deaths[5], other_deaths[5]]\n",
    "plt.bar([i for i in range(len(events))], events, tick_label=['Do nothing','NN','MC 100 iter'\n",
    "                                                             ,'MC-NN 100 iter'])\n",
    "\n",
    "plt.ylabel('Other deaths/1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_switch_uses[0], switch_uses[0], mb_switch_uses[5], switch_uses[5]]\n",
    "plt.bar([i for i in range(len(events))], events, tick_label=['Do nothing','NN','MC 100 iter'\n",
    "                                                             ,'MC-NN 100 iter'])\n",
    "\n",
    "plt.ylabel('Switch used and no one dies/1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_pushes[0], pushes[0], mb_pushes[5], pushes[5]]\n",
    "plt.bar([i for i in range(len(events))], events, tick_label=['Do nothing','NN','MC 100 iter'\n",
    "                                                             ,'MC-NN 100 iter'])\n",
    "\n",
    "plt.ylabel('Push other used and no one dies/1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [mb_other[0], other[0], mb_other[5], other[5]]\n",
    "plt.bar([i for i in range(len(events))], events, tick_label=['Do nothing','NN','MC 100 iter'\n",
    "                                                             ,'MC-NN 100 iter'])\n",
    "\n",
    "plt.ylabel('Other behavior/1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model based results, no init\n",
    "# it, score\n",
    "# 1 -1.0611\n",
    "# 3 -0.9010999999999999\n",
    "# 10 -0.44580000000000003\n",
    "# 30 -0.2856\n",
    "# 100 -0.2311\n",
    "# 300 -0.21\n",
    "# 1000 -0.2019\n",
    "\n",
    "# Model based results, with init\n",
    "# 1 -0.3517\n",
    "# 3 -0.2993\n",
    "# 5 -0.27679999999999993\n",
    "# 10 -0.2627\n",
    "# 30 -0.2398\n",
    "# 100 -0.2105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
