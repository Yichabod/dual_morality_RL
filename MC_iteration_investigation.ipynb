{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from agent import Agent\n",
    "from utils import Train, OtherMask, Switch, in_bounds, generate_array\n",
    "import grid\n",
    "from graphics import display_grid\n",
    "import neural_net\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent hit by train': -5,\n",
       " 'agent pushes others': -0.5,\n",
       " 'others hit by train': -2,\n",
       " 'agent push switch': -0.2,\n",
       " 'do nothing': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testgrid.rewards_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_must_move = {'train':(2,0),'agent':(2,2),'other1':(0,1),'switch':(0,0),'other1num':1}\n",
    "#optimal reward: 0\n",
    "init_must_push = {'train':(2,0),'agent':(4,3),'other1':(2,3),'switch':(0,0),'other1num':1}\n",
    "    # the default grid setup means agent must hit switch for optimal payoff\n",
    "#optimal reward: -0.5\n",
    "init_must_kill = {'train':(2,0),'agent':(4,1),'other1':(3,2),'switch':(0,0),'other2':(2,4),'other1num':1,'other2num':4}\n",
    "#optimal reward: -2.5\n",
    "init_hit_switch = {'train':(2,0),'agent':(4,0),'other1':(0,0),'switch':(3,2),'other2':(2,4),'other1num':1,'other2num':4}\n",
    "#optimal reward: -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fails 0.98\n"
     ]
    }
   ],
   "source": [
    "# MODEL BASED INVESTIGATION\n",
    "testgrid = grid.Grid(5,init_pos=init_hit_switch)\n",
    "agent = Agent()\n",
    "fails = 0\n",
    "trials = 50\n",
    "mc_iters = 10\n",
    "for i in range(trials):\n",
    "    Q, policy = agent.mc_first_visit_control(testgrid.copy(), mc_iters)\n",
    "    _,_, reward = agent.run_final_policy(testgrid.copy(), Q,nn_init=False,display=False)\n",
    "    fails = fails + 1 if reward < -2.5 else fails\n",
    "\n",
    "print(\"fails\",fails/trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INVESTIGATION OF MC POLICY:\n",
    "\n",
    "For just getting out of the way of the train:\n",
    "At 10 iters, agent dies 0.19 of the time. At 20 iters, it decreases to 0.04. At 30, it's less than 0.02. Above 30 iterations, the MC algorithm effectively solves the environment.\n",
    "\n",
    "For pushing another agent out of the way of the train (timing is important):\n",
    "At 10,000 iterations, the MC first visit will let the agent die 0.2 of the time. At 20,000 iterations, the agent will always save the other person.\n",
    "\n",
    "For needing to push 1 person into way of the train to save 5:\n",
    "At 1000 iterations, agent will always push the first agent. At 100 iterations, the agent will push 0.98 of the time. Even at 30 iterations, the agent will push 0.7 of the time. If acting randomly, we would expect the agent to push 0.33 \\* 0.25 = 0.083 of the time.\n",
    "\n",
    "For needing to hit the switch to save 5 people:\n",
    "At 100 iterations, agent always hits the switch. At 50 iterations, it fails 0.1 of the time. At 10 iterations, it fails 0.98 of the time.\n",
    "\n",
    "NOTE: one key parameter that affects how long the MC agent takes is how many actions in a row the agent has to take to do the correct thing. For example, if the agent is 2 squares away from the switch, it takes only 3 correct actions in a row to hit the switch (it would do this 0.2^3 of the time anyways). If the agent is 4 squares away, it would only reach the correct sequence of actions 0.2^5 of the time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fails 0.0\n"
     ]
    }
   ],
   "source": [
    "testgrid = grid.Grid(5,init_pos=init_hit_switch)\n",
    "agent = Agent()\n",
    "fails = 0\n",
    "trials = 50\n",
    "mc_iters = 50\n",
    "for i in range(trials):\n",
    "    Q, policy = agent.mc_first_visit_control(testgrid.copy(), mc_iters, nn_init=True)\n",
    "    _,_, reward = agent.run_final_policy(testgrid.copy(), Q,nn_init=True,display=False)\n",
    "    fails = fails + 1 if reward < -0.2 else fails\n",
    "\n",
    "print(\"fails\",fails/trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INVESTIGATION OF DUAL MODEL POLICY:\n",
    "\n",
    "For just getting out of the way of the train, even without any MC iterations, the dual model will always move out of the way of the train.\n",
    "\n",
    "For pushing another agent out of the way of the train (risky for the agent), at 0 iterations, the dual model pushes the person twice (the MC policy alone will push once and move backwards), and saves the agent every time. **Interestingly, at 20 iterations, the model actually does worse, failing to move the agent 0.41 of the time.** At 100 iterations, this decreases to 0.26. At 300 iterations, it is still at 0.26. At 1000 iterations, it decreases further to 0.18. At 10,000 iterations, it will always save the person\n",
    "\n",
    "For pushing 1 person into way of the train to save 5:\n",
    "At 0 iterations, the agent never pushes the 1 person. At 10 iterations, the agent will push only 0.02 of the time. At 30 iterations, the agent will only push 0.34 of the time (fails = 0.66). At 100 iterations, the agent will push 0.8 of the time (fails = 0.2)\n",
    "\n",
    "For needing to hit the switch to save 5 people:\n",
    "At 0 iterations, the agent does not know to hit the switch and so allows 4 people to die 1.0 of the time. At 5 iterations, switch is hit 0.58 of the time. At 10 iterations, the agent will hit the switch 0.8 of the time. At 50 iterations, the agent always hits the switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
